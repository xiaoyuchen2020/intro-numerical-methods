{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openml\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# # Fetch the MNIST784 dataset from OpenML\n",
    "# dataset = openml.datasets.get_dataset(554, download_data=False,download_qualities=False, download_features_meta_data=False)\n",
    "\n",
    "# # Get the data as a pandas dataframe\n",
    "# df, *_ = dataset.get_data()\n",
    "\n",
    "# # Display one random image from the dataset\n",
    "# import random\n",
    "# random_idx = random.randint(0, len(df)- 1)\n",
    "# random_image = df.iloc[random_idx, :-1].values.astype(np.float32).reshape(28, 28) # Convert to float32\n",
    "# print(random_idx)\n",
    "# # Plot the image\n",
    "# plt.imshow(random_image, cmap=\"gray\")\n",
    "# plt.title(f\"MNIST784 Image (Label: {df.iloc[random_idx,-1]})\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Representative List of \"Good looking\" MNIST Images\n",
    "# idx_list = [65223, 53589, 42820, 67231, 69885, 13231, 60713]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_patches(image, patch_size=3, stride=1):\n",
    "\n",
    "#     patches = []\n",
    "#     # Calculate how many patches we can extract in both dimensions\n",
    "#     for i in range(0, image.shape[0]- patch_size + 1, stride):\n",
    "#         for j in range(0, image.shape[1]- patch_size + 1, stride):\n",
    "#             patch = image[i:i+patch_size, j:j+patch_size]\n",
    "#             patches.append(patch)\n",
    "#     return patches\n",
    "\n",
    "# mnist_image_example = df.iloc[60713, :-1].values.astype(np.float32).reshape(28, 28)\n",
    "\n",
    "# # Extract 3x3 patches\n",
    "# patches = extract_patches(mnist_image_example, patch_size=5,stride=1)\n",
    "\n",
    "# # Verify the total number of patches and the shape of the first patch\n",
    "# total_patches = len(patches)\n",
    "# patch_shape = patches[0].shape if patches else None\n",
    "\n",
    "# total_patches, patch_shape\n",
    "\n",
    "# def visualize_patches_with_colored_titles(image, patches,  start_index=0, patch_size=5, stride=1):\n",
    "#     colors = [\"red\", \"green\", \"blue\", \"magenta\"]\n",
    "#     fig = plt.figure(figsize=(10, 5))\n",
    "#     # Plot the original image with highlighted patches\n",
    "#     ax1 = fig.add_subplot(1, 2, 1)\n",
    "#     ax1.imshow(image, cmap=\"gray\")\n",
    "#     ax1.set_title(\"Original Image\")\n",
    "#     ax1.axis(\"off\")\n",
    "    \n",
    "#     # Draw rectangles around the patches in different colors\n",
    "#     num_patches_per_row = image.shape[1]- patch_size + 1\n",
    "#     for i in range(4):\n",
    "#         if start_index + i < len(patches):\n",
    "#             row = (start_index + i) // num_patches_per_row *stride\n",
    "#             col = (start_index + i) % num_patches_per_row *stride\n",
    "#             rect = plt.Rectangle((col-0.5, row-0.5), patch_size,patch_size, linewidth=1, edgecolor=colors[i], facecolor=\"none\")\n",
    "#             ax1.add_patch(rect)\n",
    "        \n",
    "#     # Adjust subplot for the patches\n",
    "#     ax2 = fig.add_subplot(2, 4, 3)\n",
    "#     ax3 = fig.add_subplot(2, 4, 4)\n",
    "#     ax4 = fig.add_subplot(2, 4, 7)\n",
    "#     ax5 = fig.add_subplot(2, 4, 8)\n",
    "#     axs = [ax2, ax3, ax4, ax5]\n",
    "    \n",
    "#     # Plot each of the 4 patches in the adjusted subplot positions with title colors matching the rectangles\n",
    "#     for i, ax in enumerate(axs):\n",
    "#         patch_index = start_index + i\n",
    "#         if patch_index < len(patches):\n",
    "#             ax.imshow(patches[patch_index], cmap=\"gray\")\n",
    "#             ax.set_title(f\"Patch {patch_index}\", color=colors[i])\n",
    "#         ax.axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "# # Try again with the color-coordinated titles\n",
    "# visualize_patches_with_colored_titles(mnist_image_example,patches, start_index=196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patchesas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adjusted to specify just the top-left corner and the side length of the square\n",
    "# square_params = {2518: ((10.5, 13.5), 8), # Top-left (x, y) and side length for the \"2\"\n",
    "# 31540: ((10.5, 11.5), 8), # Top-left (x, y) and side length for the \"8\"\n",
    "# }\n",
    "\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# for i, idx in enumerate([2518, 31540]):\n",
    "#     plt.subplot(1, 2, i + 1)\n",
    "#     image_data = df.drop(columns=[\"class\"]).iloc[idx].values.reshape(28, 28)\n",
    "#     plt.imshow(image_data, cmap=\"gray\")\n",
    "    \n",
    "#     top_left, side_length = square_params[idx]\n",
    "    \n",
    "#     patch = patches.Rectangle(top_left, side_length, side_length,linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
    "#     plt.gca().add_patch(patch)\n",
    "    \n",
    "#     plt.title(f\"Index: {idx}\")\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "# plt.show()\n",
    " \n",
    "# def extract_patches(image, patch_size=3, stride=1):\n",
    "#     patches = []\n",
    "#     for i in range(0, image.shape[0]- patch_size + 1, stride):\n",
    "#         for j in range(0, image.shape[1]- patch_size + 1, stride):\n",
    "#             patch = image[i:i+patch_size, j:j+patch_size]\n",
    "#             patches.append(patch)\n",
    "#     return patches\n",
    "\n",
    "# mnist_image_example = df.iloc[60713, :-1].values.astype(np. float32).reshape(28, 28)\n",
    "# patches = extract_patches(mnist_image_example, patch_size=5, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# def visualize_patches(patches, patch_size=16):\n",
    "#     total_patches = len(patches)\n",
    "#     grid_size = int(np.ceil(np.sqrt(total_patches)))\n",
    "#     fig, axs = plt.subplots(grid_size, grid_size, figsize=(grid_size * 2, grid_size * 2))\n",
    "    \n",
    "#     if total_patches == 1:\n",
    "#         axs = np.array([[axs]])\n",
    "#     elif grid_size == 1:\n",
    "#         axs = np.expand_dims(axs, 0)\n",
    "        \n",
    "#     for i in range(grid_size ** 2):\n",
    "#         row = i // grid_size\n",
    "#         col = i % grid_size\n",
    "#         if i < total_patches:\n",
    "#             axs[row, col].imshow(patches[i], cmap=\"gray\", aspect= \"auto\")\n",
    "#             axs[row, col].axis(\"off\")\n",
    "#         else:\n",
    "#             axs[row, col].axis(\"off\")\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "# visualize_patches(patches, patch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\31040\\anaconda3\\envs\\gp\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\31040\\anaconda3\\envs\\gp\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\31040\\anaconda3\\envs\\gp\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gpflow\n",
    "from gpflow.kernels import Kernel\n",
    "from gpflow.utilities import positive\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = openml.datasets.get_dataset(554, download_data=True)\n",
    "X, y, _, attribute_names = mnist.get_data(target=mnist.default_target_attribute)\n",
    "\n",
    "X_np = np.array(X)\n",
    "mnist_subset_n = 50\n",
    "\n",
    "X_small = X_np[:mnist_subset_n] # Taking the first 10 images\n",
    "y_small = y[:mnist_subset_n].astype(np.float64)\n",
    "\n",
    "X_small_reshaped = X_small.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "X_small_flat = X_small_reshaped.reshape(-1, 28*28)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_small_flat, y_small, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.04705882, 0.38823529,\n",
       "       0.35686275, 0.55686275, 0.60784314, 0.96470588, 0.71372549,\n",
       "       0.60784314, 0.60784314, 0.60784314, 0.60784314, 0.51372549,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.54117647, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.98823529, 0.82352941,\n",
       "       0.47843137, 0.12941176, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.8627451 ,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.92156863, 0.74117647,\n",
       "       0.74117647, 0.74117647, 0.74117647, 0.58823529, 0.74117647,\n",
       "       0.80392157, 0.99607843, 0.99607843, 0.99607843, 0.29411765,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.1372549 , 0.29019608, 0.1372549 ,\n",
       "       0.1372549 , 0.09803922, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05098039, 0.87843137,\n",
       "       0.99607843, 0.99607843, 0.6       , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.35294118, 0.99607843, 0.99607843, 0.96862745,\n",
       "       0.20784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02352941, 0.59607843, 0.96470588,\n",
       "       0.99607843, 0.99607843, 0.19215686, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.25882353,\n",
       "       0.61960784, 0.99607843, 0.99607843, 0.97647059, 0.40392157,\n",
       "       0.03137255, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.21176471, 0.98431373, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.97254902, 0.29019608, 0.01960784, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54901961,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.79215686, 0.49019608, 0.17647059, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.22745098, 0.70980392, 0.91764706,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.98823529, 0.54901961, 0.08627451, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.11764706, 0.19607843, 0.28627451,\n",
       "       0.60784314, 0.99215686, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.74901961, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.35686275,\n",
       "       0.78431373, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.4627451 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01568627, 0.75294118,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.60392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.55294118, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.45490196, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09803922, 0.49411765, 0.3372549 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "       0.7372549 , 0.99607843, 0.99607843, 0.98039216, 0.23921569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.09411765, 0.81960784, 0.99607843,\n",
       "       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.5372549 , 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.81960784, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.65882353, 0.99607843, 0.99607843, 0.18823529, 0.03529412,\n",
       "       0.        , 0.        , 0.03529412, 0.49803922, 0.94509804,\n",
       "       0.99607843, 0.99607843, 1.        , 0.94901961, 0.24705882,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.39607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.80392157, 0.74509804, 0.74509804,\n",
       "       0.80392157, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94901961, 0.2627451 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.12941176, 0.65098039, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.98039216, 0.54117647, 0.21568627, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02745098, 0.34509804, 0.60392157, 0.45490196, 0.76078431,\n",
       "       0.76078431, 0.60392157, 0.60392157, 0.34509804, 0.19215686,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(Kernel):\n",
    "    def __init__(self, basekern, img_size, patch_size, colour_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.basekern = basekern\n",
    "        self.colour_channels = colour_channels\n",
    "        \n",
    "        self.num_patches = ((self.img_size[0]- self.patch_size[0] + 1) *(self.img_size[1]- self.patch_size[1] + 1) *colour_channels)\n",
    "        \n",
    "        self.basekern.active_dims = slice(0, np.prod(patch_size)* colour_channels)\n",
    "        \n",
    "    def _reshape_X(self, X):\n",
    "        return tf.reshape(X, (-1, self.img_size[0], self.img_size[1], self.colour_channels))\n",
    "    \n",
    "    def _extract_patches(self, X):\n",
    "        X_reshaped = self._reshape_X(X)\n",
    "        patches = tf.image.extract_patches(images=X_reshaped,sizes=[1, self.patch_size[0], self.patch_size[1], 1], strides=[1, 1, 1, 1],rates=[1, 1, 1, 1], padding=\"VALID\")\n",
    "\n",
    "        patch_dim = self.patch_size[0] * self.patch_size[1] *self.colour_channels\n",
    "        return tf.reshape(patches, [-1, self.num_patches,patch_dim])\n",
    "    \n",
    "    def K(self, X, X2=None):\n",
    "        if X2 is None:\n",
    "            X2 = X\n",
    "            \n",
    "        patches_X = self._extract_patches(X)\n",
    "        patches_X2 = self._extract_patches(X2)\n",
    "        \n",
    "        patches_X_flat = tf.reshape(patches_X, [-1, tf.shape(patches_X)[-1]])\n",
    "        patches_X2_flat = tf.reshape(patches_X2, [-1, tf.shape(patches_X2)[-1]])\n",
    "        \n",
    "        K_matrix = self.basekern.K(patches_X_flat, patches_X2_flat)\n",
    "        \n",
    "        K_matrix_reshaped = tf.reshape(K_matrix, [tf.shape(X)[0],self.num_patches, tf.shape(X2)[0], self.num_patches])\n",
    "         \n",
    "        return tf.reduce_sum(K_matrix_reshaped, axis=[1, 3]) / (self.num_patches ** 2)\n",
    "    \n",
    "    \n",
    "    def K_diag(self, X):\n",
    "        patches_X = self._extract_patches(X)\n",
    "        patches_X_flat = tf.reshape(patches_X, [-1, tf.shape(patches_X)[-1]])\n",
    "        \n",
    "        K_diag = self.basekern.K_diag(patches_X_flat)\n",
    "        \n",
    "        return tf.reduce_sum(tf.reshape(K_diag, [tf.shape(X)[0], self.num_patches]), axis=1) / self.num_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 784)\n",
      "(40,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "type(X_train)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1)\n",
      "╒══════════════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════╤═════════╤═════════╕\n",
      "│ name                             │ class     │ transform        │ prior   │ trainable   │ shape   │ dtype   │   value │\n",
      "╞══════════════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════╪═════════╪═════════╡\n",
      "│ GPR.kernel.basekern.variance     │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │       1 │\n",
      "├──────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.kernel.basekern.lengthscales │ Parameter │ Softplus         │         │ True        │ ()      │ float64 │       1 │\n",
      "├──────────────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────┼─────────┼─────────┤\n",
      "│ GPR.likelihood.variance          │ Parameter │ Softplus + Shift │         │ True        │ ()      │ float64 │       1 │\n",
      "╘══════════════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════╧═════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "base_kernel = gpflow.kernels.SquaredExponential()\n",
    "conv_kernel = Conv(basekern=base_kernel, img_size=(28, 28), patch_size=(3, 3), colour_channels=1)\n",
    " \n",
    "y_train_np = y_train.to_numpy()[:, None]\n",
    "print(y_train_np.shape)\n",
    "\n",
    "model = gpflow.models.GPR(data=(X_train, y_train_np), kernel=conv_kernel, mean_function=None)\n",
    "\n",
    "gpflow.utilities.print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time taken to optimise is 124.624 for subset size of 50\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "opt = gpflow.optimizers.Scipy()\n",
    "\n",
    "opt_logs = opt.minimize(model.training_loss, model.trainable_variables, options=dict(maxiter=100))\n",
    "end_time = time.time()\n",
    "\n",
    "opt_time = end_time- start_time\n",
    "\n",
    "print(f\" Time taken to optimise is {opt_time:.3f} for subset size of {mnist_subset_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time taken to predict is 3.171 for subset size of 50\n"
     ]
    }
   ],
   "source": [
    "mean, var = model.predict_y(X_test)\n",
    "pred_labels = np.round(mean.numpy()).astype(int)\n",
    "\n",
    "end_pred_time = time.time()- end_time\n",
    "\n",
    "print(f\" Time taken to predict is {end_pred_time:.3f} for subset size of {mnist_subset_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_images = 5\n",
    "fig, axes = plt.subplots(1, n_images, figsize=(20, 4))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_test[i].reshape(28, 28), cmap=\"gray\")\n",
    "    ax.set_title(f\"Predicted: {pred_labels[i][0]}, Actual: {y_test.iloc[i]:.0f}\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred_labels)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
